{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"U-Net.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN/ZqbiE1YIRODeTROVPK13"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"XCf3hWrDx_ih"},"source":["## U-Net\n","\n","출처 : https://medium.com/@msmapark2/u-net-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-u-net-convolutional-networks-for-biomedical-image-segmentation-456d6901b28a\n","\n","출처 : https://kuklife.tistory.com/119\n","\n","출처 : https://www.youtube.com/watch?v=O_7mR4H9WLk\n","\n","## End-to-End방식의 FCN기반 모델\n","\n","지금 End-to-End과 FCN이 무엇인가?"]},{"cell_type":"markdown","metadata":{"id":"BPvh2o6sIbGg"},"source":["## U-Net이란?\n","\n","Data augmentation??인 생각이 들기 시작한다... ㅎㅎ\n","\n","일단 왼쪽 contracting Path는 relu함수를 사용해서 VGG를 베이스로 이미지를 줄여준다.\n","\n","확장하는 Expand path는 데이터의 크기를 확장시킨다.\n","\n","이유는? augmentation같다...\n","\n","이 논문의 U-net의 장점 : 적은 데이터로 많은 데이터를 augmentation 가능?\n","\n","그러면 mask RCNN에 적용이 가능하지 않을까?\n","\n","\n","## 아키텍처 구조\n","\n","파란색 부분 = 3 X 3 Convolution(Unpadded) 블록, RELU 사용\n","\n","빨간색 부분 = 2 X 2 Max pooling(stride = 2)\n","\n","Contracting Path\n","\n","<img src = 'https://miro.medium.com/max/875/1*i_MUV1KAoILdjS_u6sAfCw.png'>\n","\n","\n","# Expansive Path\n","\n","초록색 부분 = Down-sampling을 수행하는 Max pooling 대신에 Up Convolution으로 사용\n","\n","파란색 부분 = 3 X 3 Convolution, RELU 사용\n","\n","회색 부분 = Contracting Path에서 추출된 feature map을 가져와 부착\n","\n","청록색 부분 = 마지막 단에는 1 X 1 Convolution을 두어 마지막에 cell(세포), membrane(세포막)을 구분 \n","\n","Expansive Path\n","\n","<img src = 'https://miro.medium.com/max/875/1*4BVF-6Mdpp-Z_4KBbg2dyQ.png'>\n","\n","여기서 회색 부분은 Contracting Path에서 사용한 feature map을 그대로 가져와서 사용한다\n","\n","이유 : 왼쪽의 feature map을 crop해서 오른쪽에 보내게 되는데 그 이유는 pixel에 대한 정보가 소실되는 것을 막기 위함이다. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"KPx80r50QiVf"},"source":["## U-Net의 특성\n","\n","U-Net은 기존의 sliding window 탐색 방식을 사용하지 않습니다.\n","\n","이유 : Sliding window는 탐색한 부분을 또 다시 탐색하는 방법이므로 시간과 비용을 너무 많이 사용합니다.\n","\n","U-Net의 patch 탐색 방식\n","\n","그러나 patch방법을 사용하면 6개의 구간만 나눠줘도 사진의 분석이 가능하기 때문에 시간이 빠릅니다.\n","\n","U-Net의 장점? 신기한점\n","\n","Data Augmentation Method(Elastic Deformation)\n","\n","원래 사진 데이터보다 뒤틀린 부분이 같이 반영된다.\n","\n","그러면 데이터가 실제 데이터와 비슷하게 만들어 지기 때문에 탐지에 용이하다.\n","\n","<img src = 'https://d3i71xaburhd42.cloudfront.net/661d005cd8a81547135a36f5362310637375e766/3-Figure3-1.png'>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oY28Ol6qr-xi"},"source":["## Overlap\n","\n","Method = Mirroring\n","\n","<img src = 'https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb40i94%2FbtqBFwa1fZq%2FMsCZAxhEnEgu0OdcOUsu5K%2Fimg.jpg'>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8x6VD6c9Sonz"},"source":["## Loss Function\n","\n","### $P_K (x)$ : the probability that k class is in x pixel\n","\n","k의 class가 x인 pixel에 있을 확률\n","\n","$ p_k(x) = \\frac{e^{a_k (x)}}{\\sum_{k' = 1}^{k} e^{a_{k'}(x)}}$\n","\n","where $a_k(x)$ : activation in feature channel k at thee pixel position x $\\in \\Omega$ with $\\Omega \\subset Z^2$,\n","\n","k : number of classes, $p_k (x)$ : approximated maximum function\n","\n","### w(x) : the weight map equation\n","\n","x인 pixel에 가중치를 얼마나 줄 것인가?\n","\n","$w_c$ = x의 위치에 해당하는 빈도 수\n","\n","$ w(x) = w_c(x) + w_0 * e^{- \\frac{(d_1(x) + d_2 (x))^2}{2\\sigma^2}}$\n","\n","where $w_c : \\Omega$ -> R is the weight map to balance the class frequencies\n","\n","$d_1 : \\Omega$ -> R denotes the distance to the border of the nearest cell\n","\n","$d_2 : \\Omega$ -> R denotes the distance to the border of the second nearest cell\n","\n","E(x) : Cross Entropy(Energy function)\n","\n","E = $\\sum_{x \\in \\Omega}$ w(x) log($p_{l(x)}$(x))\n","\n","Where l : $\\Omega$ -> {1, ... K} is the true label of each pixel\n","\n","w : $\\Omega$ -> R is a weight map that gives some pixels more importance in training"]},{"cell_type":"code","metadata":{"id":"mS5fbcQvxjEF"},"source":[""],"execution_count":null,"outputs":[]}]}
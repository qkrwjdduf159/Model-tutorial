{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FPN(Feature Pyramid Network).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPcOFZklfAbQ9E1Ip5bm6iC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"r4obH6MP_iG8"},"source":["## 용어 설명\n","\n","### hand crafted feature\n","\n","머신러닝에서 각 feature들의 특징들을 어떻게 추출하는지?,\n","\n"," 즉 사람이 추출하기 때문에 hand crafted feature라는 말이 붙었다.\n","\n","### End-to-End\n","\n","딥러닝에서 input과 output만 나오기 때문에 End to End라는 말이 나왔다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NBfqrg01gbnn"},"source":["## Object Detection\n","\n","CNN(Convolutional Neural Network) 모델이 하는 일은 이미지를 classification(분류) 하는 것이 목표이다.\n","\n","그래서 어떤 이미지가 들어오면 해당 이미지 내의 객체들이 무엇인지 알려주었는데, Object Detection에서는 classification 뿐만 아니라 localization이라는 개념도 포함되어있습니다.\n","\n","Object Detection = classification + localization\n","\n","즉, 객체가 있다고 판단되어 지는 지점에 직사각형(bounding box)를 그려주어서 객체를 탐지하는 방법이다.\n","\n","<img src = 'https://hoya012.github.io/assets/img/object_detection_first/fig1_cv_task.PNG'>"]},{"cell_type":"markdown","metadata":{"id":"2JQ_Xk56haTY"},"source":["## Object Detection VS Classification\n","\n","Image Classification\n","\n","image를 타겟으로 하는 확률 값이 추출된다.\n","\n","<img src = 'https://hoya012.github.io/assets/img/object_detection_first/fig2_classification_example.PNG'>\n","\n","Object Detection\n","\n","Classification task에 사물의 위치를 Bounding Box로 예측하는 Regression task가 추가된 문제.\n","\n","<img src = 'https://hoya012.github.io/assets/img/object_detection_first/fig3_detection_example.PNG'>"]},{"cell_type":"markdown","metadata":{"id":"u7X25Sfpi5SE"},"source":["## Sliding Window\n","\n","Sliding Window 기법은 딥러닝 이전에 가장 자주 사용되던 방법으로, 다양한 scale의 window를 이미지의 왼쪽 위부터 오른쪽 아래까지 sliding 하며 score를 계산하는 방식\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Pzjn3TffyBl4"},"source":["## FPN(Feature Pyramid Network)\n","\n","FPN은 네트워크에서 미리 지정한 Conv Layer마다 feature map을 추출하여 detect하는 방법입니다.\n","\n","각 데이터를 Conv를 통하여 Channel의 개수를 2배씩 늘려주며 데이터를 만들어주고,\n","\n","1*1 Conv와 위의 계층에서 upsampling nearest를 한 데이터를 더해주어 새로운 데이터를 만들어 줍니다.\n","\n","그리고 3*3 Conv를 두번 실행하여 최종 데이터를 만들어주고 SpatialDropou Upsample Activation을 진행하여 prediction을 만들어 줍니다.\n","\n","<img src = 'https://user-images.githubusercontent.com/40735375/71473487-85f66680-281a-11ea-9892-9e7cb8f90f8e.png'>\n","\n","### Upsampling nearest\n","\n","밑의 사진을 보시면, 1,2,3,4로 되어있는 행렬을 옆의 행렬처럼 만들어 주는 것을 의미합니다.\n","<img src = 'https://kharshit.github.io/img/upsampling1.png'>\n","\n","\n","<img src = 'https://ichi.pro/assets/images/max/724/1*cYACJ_ftbfWzQpMrIEvEcg.jpeg'>\n"]},{"cell_type":"markdown","metadata":{"id":"EWJi_-y9hRLt"},"source":["<img src = 'https://seongkyun.github.io/assets/post_img/papers/2019-12-06-fpn/fig6.png'>"]},{"cell_type":"code","metadata":{"id":"XpcuL8BqhQyM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rsBNQc3PgbbK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kjGfKw-KgU8T"},"source":[" "],"execution_count":null,"outputs":[]}]}